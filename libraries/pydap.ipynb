{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydap\n",
    "\n",
    "[Pydap](http://pydap.org/) [[github](https://github.com/pydap/pydap)]\n",
    "\n",
    "## Installing PyDap\n",
    "\n",
    "Pydap is on conda-forge, however the handlers and responses are only on PyPI, as well as server.\n",
    "\n",
    "It seems necessary to install [Handlers](http://pydap.org/en/latest/handlers.html), e.g.\n",
    "\n",
    "    pip install Pydap[handlers.netcdf]\n",
    "\n",
    "Similarly there are [Responses](http://pydap.org/en/latest/responses.html) that may be installed, e.g.\n",
    "\n",
    "    pip install pydap.responses.netcdf\n",
    "\n",
    "Installing the netcdf response allows `.nc` to be appended.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from rasterio.crs import CRS\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPeNDAP Review\n",
    "\n",
    "- [QuickStart - OPeNDAP Documentation](https://opendap.github.io/documentation/QuickStart.html)\n",
    "- [User Guide - OPeNDAP Documentation](https://opendap.github.io/documentation/UserGuideComprehensive.html)\n",
    "- [The Hyrax Data Server Installation and Configuration Guide - OPeNDAP Documentation](https://opendap.github.io/hyrax_guide/Master_Hyrax_Guide.html)\n",
    "\n",
    "Suffixes:\n",
    "\n",
    "- `.info`---may be most useful!\n",
    "- `.html`\n",
    "- `.dds`\n",
    "- `.das`\n",
    "- `.dods`\n",
    "- `.ascii`\n",
    "- ...\n",
    "- `.rdf`?\n",
    "\n",
    "- `.ddx`?\n",
    "\n",
    "DAP 4:\n",
    "\n",
    "- `dmr`/`dmr.html`?/`dmr.xml`/`dmr.txt`?---`.dmr`~`.dds`+`das` from DAP2\n",
    "- `dap`---~`.dods`\n",
    "- **`dsr`**---returns dataset services, new in DAP4\n",
    "- ...\n",
    "- \n",
    "\n",
    "Returns (downloads?) in native OPeNDAP binary ecoding (`.dap`), NetCDF (`.nc`, `.nc4`), GeoTIFF (`.tiff`), JPEG2000, JSON (`.json`), and ASCII (`.ascii`). ???\n",
    "\n",
    "Misc:\n",
    "\n",
    "[Authentication For DAP Clients](https://opendap.github.io/hyrax_guide/Master_Hyrax_Guide.html#_authentication_for_dap_clients) discusses Earthdata, etc. An apparently older verion is at [DAP Clients - Authenticaion](https://docs.opendap.org/index.php/DAP_Clients_-_Authentication).\n",
    "\n",
    "https://docs.opendap.org/index.php?title=DAP4_Specification\n",
    "\n",
    "- [DAP4 Specification Volume 2: DAP4 Web Services](https://docs.opendap.org/index.php?title=DAP4:_Specification_Volume_2) is useful, incl. [8 Appendix - Ancillary Web Services (Beyond DAP4)](https://docs.opendap.org/index.php?title=DAP4:_Specification_Volume_2#Appendix_-_Ancillary_Web_Services_.28Beyond_DAP4.29)\n",
    "\n",
    "https://docs.opendap.org/index.php?title=OPULS_Development\n",
    "\n",
    "https://docs.opendap.org/index.php?title=DAP4_Dataset_Services_Response\n",
    "\n",
    "https://www.unidata.ucar.edu/software/thredds/v4.6/tds/tutorial/DAP.html --- DAP 4 has new/different suffixes, not comprehensive!\n",
    "\n",
    "[Aggregation enhancements ](https://docs.opendap.org/index.php/Aggregation_enhancements) discusses [NcML](https://www.unidata.ucar.edu/software/thredds/current/netcdf-java/ncml/).\n",
    "\n",
    "The relevance of the file extension on a DAP server is unclear!? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydap Classes\n",
    "\n",
    "Pydap implemements various classess to represent [The DAP data model](http://pydap.org/en/latest/developer.html#the-dap-data-model). The [Developer documentation](http://pydap.org/en/latest/developer.html) also sheds some light on things.\n",
    "\n",
    "PyDap Types:\n",
    "\n",
    "- `DatasetType`---a `StructureType`\n",
    "- `BaseType`---data is scalar or ndarray\n",
    "- `GridType`---strangely stored with 3 vhildren, the first is the array (BaseType) and the other two are axes\n",
    "- `SequenceType`---includes `iterdata()` method\n",
    "- `StructureType`---also behave like Python dict\n",
    "\n",
    "PyDap types have attributes:\n",
    "\n",
    "1. `name`\n",
    "2. `id`\n",
    "3. `attributes`---allow lazy access (with dot)\n",
    "4. `data`\n",
    "\n",
    "Some (which?) have:\n",
    "\n",
    "- `dtype`\n",
    "- `dimensions`\n",
    "- ...\n",
    "\n",
    "You'll generally get data through a variable's `data` attribute, but note that it may be necessary to slice it like `dataset.variable[:].data` for dap to handle it properly.\n",
    "\n",
    "StructureTypes hold no data, but their `data` attribute collects data recursively from its children. Most Dap types seem to have a `children()` method but only seems relevant to StructureTypes. At least GridTypes have an `array` attribute for accessing BaseType array, so you may have to something like `dataset.variable.array[:].data`. \n",
    "\n",
    "Note that a dataset may contain a variable containing no actual data but with useful attributes!\n",
    "\n",
    "Note that variables usually act like numpy arrays, incl. things like `shape()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydap.model import DatasetType, SequenceType, GridType, StructureType, BaseType, DapType\n",
    "assert issubclass(BaseType, DapType)\n",
    "assert issubclass(StructureType, DapType)\n",
    "assert issubclass(DatasetType, StructureType)\n",
    "assert issubclass(SequenceType, StructureType)\n",
    "assert issubclass(GridType, StructureType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Using Pydap\n",
    "\n",
    "[Using the client](http://pydap.org/en/latest/client.html)\n",
    "\n",
    "Create `DatasetType` which is a fancy dict structure.\n",
    "\n",
    "Get variables using dictionary syntax or attribute style access.\n",
    "\n",
    "Variables can be `GridType`, ...?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A basic import is useless, it only gets you handlers, responses, and tests as empty namespaces!\n",
    "# To do anything you probably need to import directly. Importing these namespaces will enable tab completion for their contents.\n",
    "import pydap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure this works, it should have to be installed separately.\n",
    "# import pydap.handlers.netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydap is bizarre, \n",
    "help(pydap)\n",
    "help(pydap.handlers)\n",
    "help(pydap.responses)\n",
    "# help(pydap.tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydap.client import open_url\n",
    "url = 'http://www.ncei.noaa.gov/thredds/dodsC/namanl/201604/20160416/namanl_218_20160416_1800_000.grb'\n",
    "dataset = open_url(url)  # Create DatasetType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dataset.name)\n",
    "pprint(dataset.id)\n",
    "pprint(dataset.attributes)\n",
    "# pprint(dataset.data)  # Long output.\n",
    "\n",
    "# list(dataset.keys())\n",
    "\n",
    "# For fun, get types of the variables in the dataset.\n",
    "# pprint([type(dataset[k]) for k, v in dataset.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Temperature_surface.Temperature_surface\"]\n",
    "dataset[\"Temperature_surface\"][\"Temperature_surface\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Earthdata with Pydap\n",
    "\n",
    "Pydap used to support Earthdata auth using `pydap.utils.urs.install_basic_client()` (which seemed to read `.netrc`), but `pydap.utils` (which had to be separately installed) has gone away (no later than 1/2017). Now Earthdata auth is done using `pydap.cas.urs.setup_session()` to obtain a `requests.sessions.Session` object which is then passed to `open_url`.\n",
    "\n",
    "\n",
    "The info (`.html`) page allows you to download as NetCDF 3 or 4, or as DAP 2 or 4.\n",
    "\n",
    "The OPeNDAP directory listing ddx, dds, das, info, html, rdf, covjson, plus viewers:\n",
    "\n",
    "\n",
    "Notes:\n",
    "\n",
    "- The Dataset Viewers (viewers) leads you to:\n",
    "  - DAP2\n",
    "  - DAP4\n",
    "  - w10n Service (Webification)---adds slash after file name!\n",
    "\n",
    "\n",
    "Auth:\n",
    "\n",
    "- [How To Access Data With PyDAP | Earthdata Wiki](https://wiki.earthdata.nasa.gov/display/EL/How+To+Access+Data+With+PyDAP) discusses using `pydap.util.urs` module but that's out of date! Other examples may work?\n",
    "- [How To Access Data With Python](https://wiki.earthdata.nasa.gov/display/EL/How+To+Access+Data+With+Python) might work?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## SRTM Using OPeNDAP\n",
    "\n",
    "NASA SRTM Version 3 is available through [OPeNDAP](https://lpdaac.usgs.gov/tools/opendap/) as \n",
    "[`.ncml` files](https://opendap.cr.usgs.gov/opendap/hyrax/SRTMGL1.003/contents.html). I can't figure out how to use them as `ncml` but thankfully there is a `netcdf` directory containing [`.nc` files](https://opendap.cr.usgs.gov/opendap/hyrax/SRTMGL1.003/netcdf/contents.html).\n",
    "\n",
    "While navigating, the following services are presented for SRTM netcdf data:\n",
    "\n",
    "- [ddx](https://opendap.cr.usgs.gov/opendap/hyrax/SRTMGL1.003/netcdf/N37W120.SRTMGL1.nc.ddx)---xml\n",
    "- [dds](https://opendap.cr.usgs.gov/opendap/hyrax/SRTMGL1.003/netcdf/N37W120.SRTMGL1.nc.dds)\n",
    "- [das](https://opendap.cr.usgs.gov/opendap/hyrax/SRTMGL1.003/netcdf/N37W120.SRTMGL1.nc.das)\n",
    "- [info](https://opendap.cr.usgs.gov/opendap/hyrax/SRTMGL1.003/netcdf/N37W120.SRTMGL1.nc.info)---nice overview\n",
    "- [html](https://opendap.cr.usgs.gov/opendap/hyrax/SRTMGL1.003/netcdf/N37W120.SRTMGL1.nc.html)---same as DAP2 Service from viewers page, and file link\n",
    "- [rdf](https://opendap.cr.usgs.gov/opendap/hyrax/SRTMGL1.003/netcdf/N37W120.SRTMGL1.nc.rdf)\n",
    "- [covjson](https://opendap.cr.usgs.gov/opendap/hyrax/SRTMGL1.003/netcdf/N37W120.SRTMGL1.nc.covjson)\n",
    "\n",
    "There is also a link to viewers, which include links to the DAP2 Service (same as `html` link above) and DAP4 Service:\n",
    "\n",
    "- [dmr.html (DAP4 Service)](https://opendap.cr.usgs.gov/opendap/hyrax/SRTMGL1.003/netcdf/N37W120.SRTMGL1.nc.dmr.html)\n",
    "\n",
    "Other useful services:\n",
    "\n",
    "- [dsr](https://opendap.cr.usgs.gov/opendap/hyrax/SRTMGL1.003/netcdf/N37W120.SRTMGL1.nc.dsr)---lists all responses!\n",
    "\n",
    "The GDAL documentation for the [NetCDF: Network Common Data Form](https://www.gdal.org/frmt_netcdf.html) may be useful in deciphering the dataset.\n",
    "\n",
    "\n",
    "Relevant issues:\n",
    "\n",
    "- https://github.com/pydap/pydap/issues/20 ---!\n",
    "- https://github.com/pydap/pydap/issues/19\n",
    "- https://github.com/pydap/pydap/pull/28 ---PR merged\n",
    "- https://github.com/pydap/pydap/pull/11\n",
    "- https://github.com/pydap/pydap/pull/26\n",
    "- https://github.com/pydap/pydap/issues/51\n",
    "\n",
    "### SRTM Aside\n",
    "\n",
    "`.hgt` in 16-bit binary signed interger, in meter, row-major order, big-endian (note Intel is little-endian).\n",
    "\n",
    "Names refer to SW corner, geometric center of lower-left pixel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Open as Pydap DatasetType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read auth information from .netrc.\n",
    "import netrc\n",
    "auth = netrc.netrc()\n",
    "login, account, password = auth.authenticators('urs.earthdata.nasa.gov')\n",
    "# login, account, password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydap.client import open_url        # Or import pydap.client to make available.\n",
    "from pydap.cas.urs import setup_session  # Or import pydap.cas.urs to make available.\n",
    "\n",
    "# dataset_url = 'https://opendap.cr.usgs.gov/opendap/hyrax/SRTMGL1.003/N37W120.SRTMGL1.ncml'\n",
    "# Can't figure out how to work with nclm files, but thankfully SRTM is also available as netcdf.\n",
    "dataset_url = 'https://opendap.cr.usgs.gov/opendap/hyrax/SRTMGL1.003/netcdf/N37W120.SRTMGL1.nc'\n",
    "\n",
    "# Use login/password read from .netrc above.\n",
    "session = setup_session(username=login, password=password, check_url=dataset_url)\n",
    "dataset = open_url(dataset_url, session=session)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pydap objects contain the key attributes `name`, `id`, `attributes`, and `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.name)\n",
    "print(dataset.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `data` in DatasetType recursively contains the data of all its children we can also list the immediate children. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dataset.children())\n",
    "# list(dataset.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k, v.attributes) for k, v in dataset.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this SRTM dataset the lat and lon variables seem redundant.\n",
    "assert np.array_equal(dataset.lat[:].data, dataset.Band1.lat[:].data)\n",
    "assert np.array_equal(dataset.lon[:].data, dataset.Band1.lon[:].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are a few other urls that use Earthdata login.\n",
    "\n",
    "# ASTER DEM, works!\n",
    "# dataset_url = 'https://opendap.cr.usgs.gov/opendap/hyrax/ASTGTM.002/ASTGTM2_N37E120_dem.nc'\n",
    "\n",
    "# Another server, works!\n",
    "# dataset_url = 'https://measures.gesdisc.eosdis.nasa.gov:443/opendap/LANDMET/LANDMET_ANC_SM.1/LANDMET_ANC_SM_L3_v1.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Explore...\n",
    "# pydap.cas.urs.setup_session??\n",
    "\n",
    "# # Explore...\n",
    "# pydap.cas.urs.get_cookies.setup_session??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open as xarray Dataset using Pydap\n",
    "\n",
    "The ability to use authentication to open datasets in xarray using Pydap was added in PR [xarray#1570](https://github.com/pydata/xarray/pull/1570).\n",
    "\n",
    "Interaction is similar to using Pydap directly. Pydap `attributes` are available in xarray `attr`. However it seems that the explicit call to `.data` is not necessary as it is with Pydap, which also avoids the weirdness of GridTypes.\n",
    "\n",
    "Here we give an example using SRTM data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open authenticated datasets with xarray using pydap backend.\n",
    "# Pattern from https://github.com/pydata/xarray/pull/1570.\n",
    "\n",
    "import xarray as xr\n",
    "import pydap.cas.urs  # Make setup_session() available.\n",
    "import pydap.client   # Make open_url() available.\n",
    "\n",
    "dataset_url = 'https://opendap.cr.usgs.gov/opendap/hyrax/SRTMGL1.003/netcdf/N37W120.SRTMGL1.nc'\n",
    "\n",
    "# Instantiate session.\n",
    "session = pydap.cas.urs.setup_session(username=login, password=password, check_url=dataset_url)\n",
    "\n",
    "# Method 1: More verbose.\n",
    "# pydap_ds = pydap.client.open_url(dataset_url, session=session)\n",
    "# store = xr.backends.PydapDataStore(pydap_ds)\n",
    "# Method 2: More concise but equivalent.\n",
    "store = xr.backends.PydapDataStore.open(dataset_url, session=session)\n",
    "\n",
    "# Create xarray Dataset.\n",
    "ds = xr.open_dataset(store)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset:\n",
    "\n",
    "- dims, data_vars, coords, attrs\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get types of Dataset key properties.\n",
    "print(type(ds.dims))\n",
    "print(type(ds.data_vars))\n",
    "print(type(ds.coords))\n",
    "print(type(ds.attrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.data_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "ds.crs.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = ds.crs\n",
    "\n",
    "# crs.values\n",
    "pprint(crs.dims)\n",
    "pprint(crs.coords)\n",
    "pprint(crs.attrs)\n",
    "pprint(crs.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "---\n",
    "\n",
    "## Compare to Local DEM\n",
    "\n",
    "The original HGT files may contain more metadata than the versions accessed through DAP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from affine import Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = 'W120'\n",
    "lat = 'N37'\n",
    "url = 'https://e4ftl01.cr.usgs.gov/MEASURES/SRTMGL1.003/2000.02.11/' + lat + lon + '.SRTMGL1.hgt.zip'\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download an example SRTMGL1 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download SRTMGL1 tile to cwd.\n",
    "if not os.path.isfile(os.path.basename(url)):\n",
    "    # Based on https://wiki.earthdata.nasa.gov/display/EL/How+To+Access+Data+With+cURL+And+Wget.\n",
    "    !touch ~/.urs_cookies\n",
    "    !curl -O -b ~/.urs_cookies -c ~/.urs_cookies -L -n '{url}'\n",
    "    # !unzip '{os.path.basename(url)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script may be useful for downloading multiple files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# # Based on https://wiki.earthdata.nasa.gov/display/EL/How+To+Access+Data+With+cURL+And+Wget.\n",
    "\n",
    "# touch ~/.urs_cookies\n",
    "\n",
    "# fetch_urls() {\n",
    "#     while read -r line; do\n",
    "#     curl -b ~/.urs_cookies -c ~/.urs_cookies -L -n -f -Og $line && echo || exit_with_error \"Command failed with error. Please retrieve the data manually.\"\n",
    "#     done;\n",
    "# }\n",
    "# fetch_urls <<'EDSCEOF'\n",
    "# https://e4ftl01.cr.usgs.gov/MEASURES/SRTMGL1.003/2000.02.11/N37W120.SRTMGL1.hgt.zip\n",
    "# EDSCEOF\n",
    "\n",
    "# # Explanation of curl options:\n",
    "# # -O\n",
    "# # -b\n",
    "# # -c\n",
    "# # -L\n",
    "# # -n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open as Rasterio dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rasterio can open SRTM files using the `SRTMHGT` GDAL driver, either as `*.hgt` or directly from the zip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the *.hgt.zip file with Rasterio.\n",
    "filename = os.path.abspath(os.path.basename(url))\n",
    "dataset = rio.open(filename, driver='SRTMHGT')  # The driver is optional.\n",
    "# pprint(dataset.meta)\n",
    "pprint(dataset.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare dataset attributes of the Rasterio object with the output of gdalinfo.\n",
    "! gdalinfo '{filename}'\n",
    "# ! gdalinfo -proj4 '{filename}'\n",
    "# ! gdalinfo -json '{filename}'\n",
    "# ! gdalinfo -listmdd '{filename}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note GEOGCS implies a WKT representation.\n",
    "pprint(dataset.crs.to_dict())\n",
    "pprint(dataset.crs.to_epsg())\n",
    "pprint(dataset.crs.to_proj4())\n",
    "pprint(dataset.crs.to_string())\n",
    "pprint(dataset.crs.to_wkt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rio.crs.CRS.from_wkt(dataset.crs.to_wkt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.driver)\n",
    "print(dataset.files)\n",
    "print(dataset.shape)  # ~ width and height attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.res)\n",
    "print(dataset.tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.bounds)\n",
    "print(dataset.lnglat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.block_shapes)\n",
    "print(dataset.dtypes)\n",
    "print(dataset.colorinterp)\n",
    "print(dataset.nodatavals)  # nodata just returns the first element on nodatavals\n",
    "print(dataset.units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open as xarray DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open SRTM file with xarray.\n",
    "da = xr.open_rasterio(dataset)\n",
    "assert da.identical(xr.open_rasterio(filename))  # Could also open directly from filename.\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataArray:\n",
    "\n",
    "- values, dims, coords, attrs\n",
    "- name\n",
    "- data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get types of DataArray key properties.\n",
    "print(type(da.values))\n",
    "print(type(da.dims))\n",
    "print(type(da.coords))\n",
    "print(type(da.attrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes for the xarray DataArray are populated from some of the attributes of the Rasterio dataset.\n",
    "\n",
    "Remember that xr attributes may be read with attribute style access but live in `attrs`. \n",
    "\n",
    "Note the meta and profile attributes of Rasterio dataset also contain much of this information.\n",
    "\n",
    "It doesn't see that the Rasterio `units` attribute is reflected in xarray!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Rasterio the transform attribute is an Affine instance.\n",
    "assert np.array_equal(da.transform, dataset.transform[0:6])\n",
    "assert dataset.transform.almost_equals(da.transform)\n",
    "assert rio.transform.Affine(*da.transform) == dataset.transform\n",
    "\n",
    "assert da.crs == dataset.crs.to_string()\n",
    "assert da.res == dataset.res\n",
    "\n",
    "# In Rasterio is_tiled is a bool, but it's stored as a uint8 attribute in xarray.\n",
    "assert da.is_tiled == dataset.is_tiled\n",
    "\n",
    "assert da.nodatavals == dataset.nodatavals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.dtype == dataset.dtypes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Affine.from_gdal(*da.transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up DataArray that was opened from HGT file.\n",
    "\n",
    "# da_clean = da.copy()\n",
    "# da_clean.name = 'elevation'\n",
    "da_clean = da.rename('elevation')  # Add name property.\n",
    "da_clean = da_clean.squeeze(drop=True)    # Remove length 1 dimensions and their coordinates, in particular band.\n",
    "da_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what the DataArray would look like converted to a Dataset.\n",
    "da_clean.to_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.Band1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up Dataset that was opened from DAP, as DataSet.\n",
    "\n",
    "ds_clean = ds.rename({'Band1': 'elevation'})  # Rename Band1 variable to elevation.\n",
    "# ds_clean = ds_clean.squeeze(drop=True)    # Remove length 1 dimensions and their coordinates, in particular band.\n",
    "ds_clean\n",
    "\n",
    "# Add crs attribute.\n",
    "wkt = ds.crs.spatial_ref.replace('\\\\\"', '\"')\n",
    "crs = CRS.from_wkt(wkt).to_string()\n",
    "# Add crs attribute to elevation variable and update Dataset with it.\n",
    "new_elevation =  ds_clean.elevation.assign_attrs(crs = crs)  # Seems same as assign_attrs({'crs' : crs}).\n",
    "ds_clean = ds_clean.assign(elevation = new_elevation)  # Works.\n",
    "\n",
    "# Add transform attribute.\n",
    "geotransform = [float(s) for s in ds.crs.GeoTransform.split()]\n",
    "affine = rio.transform.Affine.from_gdal(*geotransform)\n",
    "new_elevation =  ds_clean.elevation.assign_attrs(transform = tuple(affine)[0:6])\n",
    "ds_clean = ds_clean.assign(elevation = new_elevation)\n",
    "\n",
    "# TODO change to make a crs attribute with the stuff in there?\n",
    "# Add all attrs from strange crs variable to elevation variable and update Dataset with this new value.\n",
    "new_elevation = ds_clean.elevation.assign_attrs(ds_clean.crs.attrs)\n",
    "ds_clean = ds_clean.assign(elevation = new_elevation)  # Works.\n",
    "# ds_clean = ds_clean.assign({'elevation': new_elevation})  # Works.\n",
    "# ds_clean = ds_clean.update({'elevation': new_elevation})  # Works.\n",
    "# ds_clean['elevation'] = new_elevation  # Works.\n",
    "\n",
    "# TODO remove extra junk attrs copied from crs variable to elevation variable.\n",
    "\n",
    "# Remove unneeded crs variable.\n",
    "ds_clean = ds_clean.drop('crs')\n",
    "\n",
    "ds_clean.elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that transforms are comparable.\n",
    "assert Affine(*ds_clean.elevation.transform).almost_equals(da_clean.transform)\n",
    "assert np.allclose(ds_clean.elevation.transform, da_clean.transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation = ds_clean.elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation.interp_like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da.where(da.x<-119.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da.sel(x=slice(-120, -119.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Work with CRS\n",
    "\n",
    "Make sure to:\n",
    "\n",
    "    from rasterio.crs import CRS\n",
    "\n",
    "\n",
    "It appears that there is some weirdness wrt how `rio.crs.CRS` works. The `AUTHORITY` parts of `PRIMEM` and `UNIT` don't seem to make it to Dataset `crs.spatial_ref` when opening the files locally. The CRS object created from this has the correct EPSG but the `wkt` attribute is still missing these. However, creating a new CRS object using that EPSG string results in the complete WKT.\n",
    "\n",
    "The `crs.spatial_ref` string in the xarray Dataset obtained through DAP is a funny thing. It seems to contain the pattern `\\\\\"`, which seems to be a\n",
    "\n",
    "In the NetCDF dataset the crs.spatial_ref contains escaped double quotes (`\\\"`). However when accessing with Pydap or xarray they are converted into `\\\\\"` for some reason. I believe the second backslash is added in an attempt to escape the string, ignoring the fact that it's already escaped. The resulting string is malformed and can't be fed directly to rasterio.crs.CRS functions.\n",
    "\n",
    "### WKT\n",
    "\n",
    "https://www.opengeospatial.org/standards/wkt-crs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrate that escapes are optional.\n",
    "\"\\\"\" == '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rasterio crs.\n",
    "dataset.crs.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataArray crs attribute comes from Rasterio.\n",
    "da.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string back to WKT.\n",
    "CRS.from_string(da.crs).wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print() just shows the backslash.\n",
    "print(ds.crs.spatial_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str() shows the \n",
    "str(ds.crs.spatial_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.crs.spatial_ref.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.crs.spatial_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that repr() even adds escaped opening and closing single quotes.\n",
    "repr(ds.crs.spatial_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.crs.spatial_ref.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkt = ds.crs.spatial_ref\n",
    "\n",
    "#???\n",
    "# This seems to work on the string shown by str().\n",
    "# Note print() and str() use __str__(), but escapes prob handled differently, while repr() uses __repr__().\n",
    "\n",
    "\n",
    "\n",
    "wkt = ds.crs.spatial_ref.replace('\\\\\"', '\"') # Escape just the backslash.\n",
    "# wkt = ds.crs.spatial_ref.replace(\"\\\\\\\"\", \"\\\"\")  # Escape both backslash and quote characters.\n",
    "# wkt = ds.crs.spatial_ref.replace('\\\\', '')  # Just replace the backslash, but better to include the quote as above.\n",
    "# print(wkt)\n",
    "\n",
    "crs = CRS.from_wkt(wkt)\n",
    "# CRS.from_string(wkt)\n",
    "# CRS.from_user_input(wkt)\n",
    "print(crs)\n",
    "\n",
    "# wkt\n",
    "print(wkt)\n",
    "# str(wkt)\n",
    "# repr(wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO maybe later, do the same with re.sub().\n",
    "# import re\n",
    "# re.sub('\\\\', '', ds.crs.spatial_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geospatial]",
   "language": "python",
   "name": "conda-env-geospatial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
